{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52857987",
   "metadata": {},
   "source": [
    "# 掩盖softmax层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495cbe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "tf.Tensor(\n",
      "[[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]\n",
      "  [10. 11. 12. 13. 14.]\n",
      "  [15. 16. 17. 18. 19.]]\n",
      "\n",
      " [[20. 21. 22. 23. 24.]\n",
      "  [25. 26. 27. 28. 29.]\n",
      "  [30. 31. 32. 33. 34.]\n",
      "  [35. 36. 37. 38. 39.]]\n",
      "\n",
      " [[40. 41. 42. 43. 44.]\n",
      "  [45. 46. 47. 48. 49.]\n",
      "  [50. 51. 52. 53. 54.]\n",
      "  [55. 56. 57. 58. 59.]]\n",
      "\n",
      " [[60. 61. 62. 63. 64.]\n",
      "  [65. 66. 67. 68. 69.]\n",
      "  [70. 71. 72. 73. 74.]\n",
      "  [75. 76. 77. 78. 79.]]\n",
      "\n",
      " [[80. 81. 82. 83. 84.]\n",
      "  [85. 86. 87. 88. 89.]\n",
      "  [90. 91. 92. 93. 94.]\n",
      "  [95. 96. 97. 98. 99.]]], shape=(5, 4, 5), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 22:05:57.227454: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-24 22:05:57.227478: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4, 5), dtype=float32, numpy=\n",
       "array([[[0.09003057, 0.24472848, 0.665241  , 0.        , 0.        ],\n",
       "        [0.09003057, 0.24472848, 0.665241  , 0.        , 0.        ],\n",
       "        [0.09003057, 0.24472848, 0.665241  , 0.        , 0.        ],\n",
       "        [0.09003057, 0.24472848, 0.665241  , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.2689414 , 0.7310586 , 0.        , 0.        , 0.        ],\n",
       "        [0.2689414 , 0.7310586 , 0.        , 0.        , 0.        ],\n",
       "        [0.2689414 , 0.7310586 , 0.        , 0.        , 0.        ],\n",
       "        [0.2689414 , 0.7310586 , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.09003057, 0.24472848, 0.665241  , 0.        , 0.        ],\n",
       "        [0.09003057, 0.24472848, 0.665241  , 0.        , 0.        ],\n",
       "        [0.09003057, 0.24472848, 0.665241  , 0.        , 0.        ],\n",
       "        [0.09003057, 0.24472848, 0.665241  , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\n",
       "        [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\n",
       "        [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\n",
       "        [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def sequence_mask(x, valid_lens, value):\n",
    "    mask = tf.range(start=0, limit=x.shape[1], dtype=tf.float32)[None, :] < tf.cast(valid_lens, dtype=tf.float32)[:, None]\n",
    "    if len(x.shape) == 3:\n",
    "        return tf.where(tf.expand_dims(mask, axis=-1), x, value)\n",
    "    else:\n",
    "        return tf.where(mask, x, value)\n",
    "    print(x)\n",
    "   \n",
    "\n",
    "def mask_softmax(x, valid_lens):\n",
    "    # x[valid_len: ] = -1e6\n",
    "    # softmax(x)\n",
    "    x_shape = x.shape\n",
    "    if valid_lens is None:\n",
    "        return tf.nn.softmax(x, axis=-1)\n",
    "    if len(valid_lens.shape) == 1:\n",
    "        valid_lens = tf.repeat(valid_lens, repeats=x_shape[1])\n",
    "    else:\n",
    "        valid_lens = tf.reshape(valid_lens, shape=-1)\n",
    "    x = tf.reshape(x, shape=(-1, x_shape[-1]))\n",
    "    # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "    x = sequence_mask(x, valid_lens, -1e6)\n",
    "    x = tf.reshape(x, x_shape)\n",
    "    return tf.nn.softmax(x, axis=-1)\n",
    "\n",
    "\n",
    "x = tf.reshape(tf.range(100, dtype=tf.float32), shape=(-1, 4, 5))\n",
    "print(x)\n",
    "valid_lens = tf.constant([\n",
    "   3, 2, 1, 3, 0\n",
    "])\n",
    "mask_softmax(x, valid_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cad6fa",
   "metadata": {},
   "source": [
    "# 加性注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37a9c97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-1.0442429e+00  4.6222693e-01  3.7916511e-01  9.6615148e-01\n",
      "    2.2189447e-01 -8.8808823e-01 -7.3989734e-02  9.1667759e-01]\n",
      "  [-1.0697777e+00  4.8217595e-01  3.5096878e-01  9.5816904e-01\n",
      "    2.3972003e-01 -8.5897088e-01 -7.4246027e-02  9.7011662e-01]\n",
      "  [-1.0476183e+00  4.6486390e-01  3.7543803e-01  9.6509635e-01\n",
      "    2.2425075e-01 -8.8423938e-01 -7.4023619e-02  9.2374146e-01]]\n",
      "\n",
      " [[-3.5058373e-01  2.4638353e-01 -1.8569909e-01  8.9326613e-02\n",
      "    7.0472521e-01 -4.0818244e-01  2.7468809e-01  1.8326432e-01]\n",
      "  [-2.2051618e-01  2.3597541e-01 -8.0913305e-06  1.4171034e-01\n",
      "    4.8823899e-01 -4.7554746e-01  5.2522027e-01  3.4304345e-01]\n",
      "  [-3.5547799e-01  2.0611273e-01  7.7304140e-02  2.7947500e-01\n",
      "    5.2542472e-01 -4.6053749e-01  3.7951532e-01  2.9996064e-01]]], shape=(2, 3, 8), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.75249153 0.24750847 0.         0.         0.        ]\n",
      "  [0.7728675  0.2271325  0.         0.         0.        ]\n",
      "  [0.75518495 0.24481508 0.         0.         0.        ]]\n",
      "\n",
      " [[0.21331158 0.2622315  0.21623395 0.30822295 0.        ]\n",
      "  [0.24104366 0.31615683 0.31420618 0.12859331 0.        ]\n",
      "  [0.27067634 0.34799954 0.22184339 0.1594808  0.        ]]], shape=(2, 3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from attention import AdditiveAttentionLayer\n",
    "\n",
    "attention = AdditiveAttentionLayer(num_hidden=20, dropout=0.1)\n",
    "queries = tf.random.normal(shape=(2, 3, 20))\n",
    "keys = tf.random.normal(shape=(2, 5, 7))\n",
    "values = tf.random.normal(shape=(2, 5, 8))\n",
    "valid_lens = tf.constant([\n",
    "    2, 4\n",
    "])\n",
    "\n",
    "scores = attention(queries, keys, values, valid_lens)\n",
    "print(scores)\n",
    "print(attention.attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a04ae6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 2.  3.  4.  5.]]\n",
      "\n",
      " [[10. 11. 12. 13.]]], shape=(2, 1, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0.5        0.5        0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667\n",
      "   0.         0.         0.         0.        ]]], shape=(2, 1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "queries, keys = tf.random.normal(shape=(2, 1, 20)), tf.ones((2, 10, 2))\n",
    "# values的小批量，两个值矩阵是相同的\n",
    "values = tf.repeat(tf.reshape(\n",
    "    tf.range(40, dtype=tf.float32), shape=(1, 10, 4)), repeats=2, axis=0)\n",
    "valid_lens = tf.constant([2, 6])\n",
    "attention = AdditiveAttentionLayer(num_hidden=20, dropout=0.1)\n",
    "\n",
    "scores=attention(queries, keys, values, valid_lens, training=False)\n",
    "print(scores)\n",
    "print(attention.attention_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286e177",
   "metadata": {},
   "source": [
    "# Bahdanau注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac08049",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da5fc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building source vocab...\n",
      "building targe vocab...\n",
      "converting x to enc_x...\n",
      "converting y to dec_x...\n",
      "case count: 512\n",
      "source: \n",
      "  vocab size: 233\n",
      "  enc_x avg len: 2.994140625\n",
      "  enc_x max len: 4\n",
      "targe: \n",
      "  vocab size: 497\n",
      "  dec_x avg len: 4.14453125\n",
      "  dec_x max len: 6\n"
     ]
    }
   ],
   "source": [
    "from datasets import EnglishChineseTranslateDatasets, EnglishFrenchTranslateDatasets\n",
    "from data_generator import TranslateDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# ds = EnglishChineseTranslateDatasets()\n",
    "ds = EnglishFrenchTranslateDatasets()\n",
    "test_x, test_y = ds.load_test_data()\n",
    "test_x, test_y = test_x[: 512], test_y[: 512]\n",
    "gen = TranslateDataGenerator(\n",
    "    test_x, test_y, x_sentence_len=5, y_sentence_len=5, min_freq=0\n",
    ")\n",
    "\n",
    "gen.summary()\n",
    "enc_x, x_len, dec_x, y_len, target_y = gen[: 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf6cf8",
   "metadata": {},
   "source": [
    "## 模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50badf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate_model import AttentionSeq2SeqTranslateModel\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "m = AttentionSeq2SeqTranslateModel(\n",
    "    enc_vocab_size=len(gen.x_vocab), enc_embedding_size=256,\n",
    "    dec_vocab_size=len(gen.y_vocab), dec_embedding_size=256,\n",
    "    dropout=0.1, gru_layers=2, gru_hidden_units=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e798fe5",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0ac4563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cases: 512\n",
      "train 25 epochs for learning rate 0.008\n",
      "Epoch 1/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 1, Loss: 4.2390\n",
      "Epoch 2/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 2, Loss: 3.6877\n",
      "Epoch 3/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 3, Loss: 3.2126\n",
      "Epoch 4/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 4, Loss: 3.0942\n",
      "Epoch 5/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 5, Loss: 2.9473\n",
      "Epoch 6/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 6, Loss: 2.8063\n",
      "Epoch 7/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 7, Loss: 2.7523\n",
      "Epoch 8/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 8, Loss: 2.5902\n",
      "Epoch 9/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 9, Loss: 2.4387\n",
      "Epoch 10/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 10, Loss: 2.3035\n",
      "Epoch 11/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 11, Loss: 2.1510\n",
      "Epoch 12/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 12, Loss: 2.0000\n",
      "Epoch 13/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 13, Loss: 1.9235\n",
      "Epoch 14/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 14, Loss: 1.7852\n",
      "Epoch 15/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 15, Loss: 1.6798\n",
      "Epoch 16/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 16, Loss: 1.5685\n",
      "Epoch 17/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 17, Loss: 1.4290\n",
      "Epoch 18/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 18, Loss: 1.3421\n",
      "Epoch 19/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 19, Loss: 1.2962\n",
      "Epoch 20/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 20, Loss: 1.2199\n",
      "Epoch 21/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 21, Loss: 1.1706\n",
      "Epoch 22/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 22, Loss: 1.1040\n",
      "Epoch 23/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 23, Loss: 1.0837\n",
      "Epoch 24/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 24, Loss: 1.0231\n",
      "Epoch 25/25\n",
      "[=========================================================================] 100%\n",
      "Epoch 25, Loss: 0.9506\n",
      "train 50 epochs for learning rate 0.005\n",
      "Epoch 1/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 1, Loss: 1.0746\n",
      "Epoch 2/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 2, Loss: 0.8555\n",
      "Epoch 3/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 3, Loss: 0.9249\n",
      "Epoch 4/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 4, Loss: 0.8709\n",
      "Epoch 5/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 5, Loss: 0.7398\n",
      "Epoch 6/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 6, Loss: 0.6485\n",
      "Epoch 7/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 7, Loss: 0.5972\n",
      "Epoch 8/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 8, Loss: 0.5522\n",
      "Epoch 9/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 9, Loss: 0.5125\n",
      "Epoch 10/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 10, Loss: 0.4866\n",
      "Epoch 11/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 11, Loss: 0.4361\n",
      "Epoch 12/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 12, Loss: 0.4075\n",
      "Epoch 13/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 13, Loss: 0.3895\n",
      "Epoch 14/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 14, Loss: 0.3387\n",
      "Epoch 15/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 15, Loss: 0.2953\n",
      "Epoch 16/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 16, Loss: 0.2730\n",
      "Epoch 17/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 17, Loss: 0.2594\n",
      "Epoch 18/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 18, Loss: 0.2608\n",
      "Epoch 19/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 19, Loss: 0.2911\n",
      "Epoch 20/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 20, Loss: 0.2654\n",
      "Epoch 21/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 21, Loss: 0.2948\n",
      "Epoch 22/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 22, Loss: 0.2757\n",
      "Epoch 23/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 23, Loss: 0.2469\n",
      "Epoch 24/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 24, Loss: 0.2004\n",
      "Epoch 25/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 25, Loss: 0.1750\n",
      "Epoch 26/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 26, Loss: 0.1670\n",
      "Epoch 27/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 27, Loss: 0.1358\n",
      "Epoch 28/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 28, Loss: 0.1171\n",
      "Epoch 29/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 29, Loss: 0.0951\n",
      "Epoch 30/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 30, Loss: 0.0805\n",
      "Epoch 31/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 31, Loss: 0.0697\n",
      "Epoch 32/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 32, Loss: 0.0615\n",
      "Epoch 33/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 33, Loss: 0.0575\n",
      "Epoch 34/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 34, Loss: 0.0582\n",
      "Epoch 35/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 35, Loss: 0.0679\n",
      "Epoch 36/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 36, Loss: 0.0598\n",
      "Epoch 37/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 37, Loss: 0.0498\n",
      "Epoch 38/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 38, Loss: 0.0451\n",
      "Epoch 39/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 39, Loss: 0.0405\n",
      "Epoch 40/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 40, Loss: 0.0408\n",
      "Epoch 41/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 41, Loss: 0.0405\n",
      "Epoch 42/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 42, Loss: 0.0399\n",
      "Epoch 43/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 43, Loss: 0.0374\n",
      "Epoch 44/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 44, Loss: 0.0328\n",
      "Epoch 45/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 45, Loss: 0.0317\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================================================] 100%\n",
      "Epoch 46, Loss: 0.0275\n",
      "Epoch 47/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 47, Loss: 0.0250\n",
      "Epoch 48/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 48, Loss: 0.0233\n",
      "Epoch 49/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 49, Loss: 0.0237\n",
      "Epoch 50/50\n",
      "[=========================================================================] 100%\n",
      "Epoch 50, Loss: 0.0258\n",
      "train 75 epochs for learning rate 0.003\n",
      "Epoch 1/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 1, Loss: 0.0327\n",
      "Epoch 2/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 2, Loss: 0.0447\n",
      "Epoch 3/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 3, Loss: 0.0627\n",
      "Epoch 4/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 4, Loss: 0.0651\n",
      "Epoch 5/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 5, Loss: 0.0455\n",
      "Epoch 6/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 6, Loss: 0.0309\n",
      "Epoch 7/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 7, Loss: 0.0320\n",
      "Epoch 8/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 8, Loss: 0.0219\n",
      "Epoch 9/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 9, Loss: 0.0182\n",
      "Epoch 10/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 10, Loss: 0.0135\n",
      "Epoch 11/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 11, Loss: 0.0120\n",
      "Epoch 12/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 12, Loss: 0.0100\n",
      "Epoch 13/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 13, Loss: 0.0088\n",
      "Epoch 14/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 14, Loss: 0.0077\n",
      "Epoch 15/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 15, Loss: 0.0075\n",
      "Epoch 16/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 16, Loss: 0.0073\n",
      "Epoch 17/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 17, Loss: 0.0070\n",
      "Epoch 18/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 18, Loss: 0.0065\n",
      "Epoch 19/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 19, Loss: 0.0059\n",
      "Epoch 20/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 20, Loss: 0.0056\n",
      "Epoch 21/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 21, Loss: 0.0053\n",
      "Epoch 22/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 22, Loss: 0.0050\n",
      "Epoch 23/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 23, Loss: 0.0048\n",
      "Epoch 24/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 24, Loss: 0.0046\n",
      "Epoch 25/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 25, Loss: 0.0044\n",
      "Epoch 26/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 26, Loss: 0.0043\n",
      "Epoch 27/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 27, Loss: 0.0041\n",
      "Epoch 28/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 28, Loss: 0.0040\n",
      "Epoch 29/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 29, Loss: 0.0039\n",
      "Epoch 30/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 30, Loss: 0.0038\n",
      "Epoch 31/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 31, Loss: 0.0037\n",
      "Epoch 32/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 32, Loss: 0.0036\n",
      "Epoch 33/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 33, Loss: 0.0035\n",
      "Epoch 34/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 34, Loss: 0.0034\n",
      "Epoch 35/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 35, Loss: 0.0034\n",
      "Epoch 36/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 36, Loss: 0.0038\n",
      "Epoch 37/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 37, Loss: 0.0037\n",
      "Epoch 38/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 38, Loss: 0.0036\n",
      "Epoch 39/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 39, Loss: 0.0036\n",
      "Epoch 40/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 40, Loss: 0.0037\n",
      "Epoch 41/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 41, Loss: 0.0037\n",
      "Epoch 42/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 42, Loss: 0.0036\n",
      "Epoch 43/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 43, Loss: 0.0036\n",
      "Epoch 44/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 44, Loss: 0.0042\n",
      "Epoch 45/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 45, Loss: 0.0062\n",
      "Epoch 46/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 46, Loss: 0.0071\n",
      "Epoch 47/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 47, Loss: 0.0102\n",
      "Epoch 48/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 48, Loss: 0.0091\n",
      "Epoch 49/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 49, Loss: 0.0112\n",
      "Epoch 50/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 50, Loss: 0.0171\n",
      "Epoch 51/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 51, Loss: 0.0216\n",
      "Epoch 52/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 52, Loss: 0.0231\n",
      "Epoch 53/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 53, Loss: 0.0727\n",
      "Epoch 54/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 54, Loss: 0.0838\n",
      "Epoch 55/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 55, Loss: 0.1610\n",
      "Epoch 56/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 56, Loss: 0.3107\n",
      "Epoch 57/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 57, Loss: 0.1789\n",
      "Epoch 58/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 58, Loss: 0.1724\n",
      "Epoch 59/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 59, Loss: 0.1327\n",
      "Epoch 60/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 60, Loss: 0.1159\n",
      "Epoch 61/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 61, Loss: 0.1041\n",
      "Epoch 62/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 62, Loss: 0.0894\n",
      "Epoch 63/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 63, Loss: 0.0773\n",
      "Epoch 64/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 64, Loss: 0.0568\n",
      "Epoch 65/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 65, Loss: 0.0374\n",
      "Epoch 66/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================================================] 100%\n",
      "Epoch 66, Loss: 0.0399\n",
      "Epoch 67/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 67, Loss: 0.0239\n",
      "Epoch 68/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 68, Loss: 0.0240\n",
      "Epoch 69/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 69, Loss: 0.0131\n",
      "Epoch 70/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 70, Loss: 0.0125\n",
      "Epoch 71/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 71, Loss: 0.0145\n",
      "Epoch 72/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 72, Loss: 0.0289\n",
      "Epoch 73/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 73, Loss: 0.0152\n",
      "Epoch 74/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 74, Loss: 0.0203\n",
      "Epoch 75/75\n",
      "[=========================================================================] 100%\n",
      "Epoch 75, Loss: 0.0128\n",
      "train 100 epochs for learning rate 0.001\n",
      "Epoch 1/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 1, Loss: 0.0099\n",
      "Epoch 2/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 2, Loss: 0.0069\n",
      "Epoch 3/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 3, Loss: 0.0057\n",
      "Epoch 4/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 4, Loss: 0.0046\n",
      "Epoch 5/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 5, Loss: 0.0039\n",
      "Epoch 6/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 6, Loss: 0.0033\n",
      "Epoch 7/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 7, Loss: 0.0031\n",
      "Epoch 8/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 8, Loss: 0.0027\n",
      "Epoch 9/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 9, Loss: 0.0025\n",
      "Epoch 10/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 10, Loss: 0.0023\n",
      "Epoch 11/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 11, Loss: 0.0021\n",
      "Epoch 12/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 12, Loss: 0.0020\n",
      "Epoch 13/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 13, Loss: 0.0019\n",
      "Epoch 14/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 14, Loss: 0.0018\n",
      "Epoch 15/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 15, Loss: 0.0016\n",
      "Epoch 16/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 16, Loss: 0.0016\n",
      "Epoch 17/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 17, Loss: 0.0015\n",
      "Epoch 18/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 18, Loss: 0.0014\n",
      "Epoch 19/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 19, Loss: 0.0013\n",
      "Epoch 20/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 20, Loss: 0.0013\n",
      "Epoch 21/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 21, Loss: 0.0012\n",
      "Epoch 22/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 22, Loss: 0.0012\n",
      "Epoch 23/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 23, Loss: 0.0011\n",
      "Epoch 24/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 24, Loss: 0.0011\n",
      "Epoch 25/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 25, Loss: 0.0011\n",
      "Epoch 26/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 26, Loss: 0.0010\n",
      "Epoch 27/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 27, Loss: 0.0010\n",
      "Epoch 28/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 28, Loss: 0.0010\n",
      "Epoch 29/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 29, Loss: 0.0009\n",
      "Epoch 30/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 30, Loss: 0.0009\n",
      "Epoch 31/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 31, Loss: 0.0009\n",
      "Epoch 32/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 32, Loss: 0.0009\n",
      "Epoch 33/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 33, Loss: 0.0008\n",
      "Epoch 34/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 34, Loss: 0.0008\n",
      "Epoch 35/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 35, Loss: 0.0008\n",
      "Epoch 36/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 36, Loss: 0.0008\n",
      "Epoch 37/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 37, Loss: 0.0008\n",
      "Epoch 38/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 38, Loss: 0.0007\n",
      "Epoch 39/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 39, Loss: 0.0007\n",
      "Epoch 40/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 40, Loss: 0.0007\n",
      "Epoch 41/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 41, Loss: 0.0007\n",
      "Epoch 42/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 42, Loss: 0.0007\n",
      "Epoch 43/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 43, Loss: 0.0007\n",
      "Epoch 44/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 44, Loss: 0.0007\n",
      "Epoch 45/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 45, Loss: 0.0007\n",
      "Epoch 46/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 46, Loss: 0.0006\n",
      "Epoch 47/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 47, Loss: 0.0006\n",
      "Epoch 48/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 48, Loss: 0.0006\n",
      "Epoch 49/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 49, Loss: 0.0006\n",
      "Epoch 50/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 50, Loss: 0.0006\n",
      "Epoch 51/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 51, Loss: 0.0006\n",
      "Epoch 52/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 52, Loss: 0.0006\n",
      "Epoch 53/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 53, Loss: 0.0006\n",
      "Epoch 54/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 54, Loss: 0.0005\n",
      "Epoch 55/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 55, Loss: 0.0005\n",
      "Epoch 56/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 56, Loss: 0.0005\n",
      "Epoch 57/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 57, Loss: 0.0006\n",
      "Epoch 58/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 58, Loss: 0.0008\n",
      "Epoch 59/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 59, Loss: 0.0007\n",
      "Epoch 60/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 60, Loss: 0.0007\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================================================] 100%\n",
      "Epoch 61, Loss: 0.0008\n",
      "Epoch 62/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 62, Loss: 0.0007\n",
      "Epoch 63/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 63, Loss: 0.0007\n",
      "Epoch 64/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 64, Loss: 0.0006\n",
      "Epoch 65/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 65, Loss: 0.0006\n",
      "Epoch 66/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 66, Loss: 0.0006\n",
      "Epoch 67/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 67, Loss: 0.0005\n",
      "Epoch 68/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 68, Loss: 0.0005\n",
      "Epoch 69/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 69, Loss: 0.0005\n",
      "Epoch 70/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 70, Loss: 0.0005\n",
      "Epoch 71/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 71, Loss: 0.0005\n",
      "Epoch 72/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 72, Loss: 0.0005\n",
      "Epoch 73/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 73, Loss: 0.0005\n",
      "Epoch 74/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 74, Loss: 0.0005\n",
      "Epoch 75/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 75, Loss: 0.0005\n",
      "Epoch 76/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 76, Loss: 0.0004\n",
      "Epoch 77/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 77, Loss: 0.0004\n",
      "Epoch 78/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 78, Loss: 0.0004\n",
      "Epoch 79/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 79, Loss: 0.0004\n",
      "Epoch 80/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 80, Loss: 0.0004\n",
      "Epoch 81/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 81, Loss: 0.0004\n",
      "Epoch 82/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 82, Loss: 0.0004\n",
      "Epoch 83/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 83, Loss: 0.0004\n",
      "Epoch 84/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 84, Loss: 0.0004\n",
      "Epoch 85/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 85, Loss: 0.0004\n",
      "Epoch 86/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 86, Loss: 0.0004\n",
      "Epoch 87/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 87, Loss: 0.0004\n",
      "Epoch 88/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 88, Loss: 0.0004\n",
      "Epoch 89/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 89, Loss: 0.0004\n",
      "Epoch 90/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 90, Loss: 0.0004\n",
      "Epoch 91/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 91, Loss: 0.0004\n",
      "Epoch 92/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 92, Loss: 0.0003\n",
      "Epoch 93/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 93, Loss: 0.0003\n",
      "Epoch 94/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 94, Loss: 0.0003\n",
      "Epoch 95/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 95, Loss: 0.0003\n",
      "Epoch 96/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 96, Loss: 0.0003\n",
      "Epoch 97/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 97, Loss: 0.0003\n",
      "Epoch 98/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 98, Loss: 0.0003\n",
      "Epoch 99/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 99, Loss: 0.0003\n",
      "Epoch 100/100\n",
      "[=========================================================================] 100%\n",
      "Epoch 100, Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "print(f\"all cases: {len(gen)}\")\n",
    "lr_list=[8e-3, 5e-3, 3e-3, 1e-3]\n",
    "for i, lr in enumerate(lr_list):\n",
    "    epochs=25 * (i + 1)\n",
    "    print(f\"train {epochs} epochs for learning rate {lr}\")\n",
    "    m.custom_fit(\n",
    "        gen,\n",
    "        batch_size=128,\n",
    "        epochs=epochs,\n",
    "        learning_rate=lr\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9365f7",
   "metadata": {},
   "source": [
    "## 翻译测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f1fcbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come in . 3\n",
      "['come', 'in', '.', '<pad>', '<pad>']\n",
      "entrez ! 3\n",
      "['<bos>', 'entrez', '!', '<pad>', '<pad>']\n",
      "['entrez', '!', '<eos>', '<pad>', '<pad>']\n",
      "entrez !\n"
     ]
    }
   ],
   "source": [
    "idx = 100\n",
    "sub_enc_x, sub_enc_valid_len, sub_dec_x, sub_target_valid_len, sub_target_y = gen[idx: idx + 1]\n",
    "print(gen.x[idx], sub_enc_valid_len[0])\n",
    "print(gen.x_vocab.to_tokens(list(sub_enc_x[0])))\n",
    "print(gen.y[idx], sub_target_valid_len[0])\n",
    "print(gen.y_vocab.to_tokens(list(sub_dec_x[0])))\n",
    "print(gen.y_vocab.to_tokens(list(sub_target_y[0])))\n",
    "\n",
    "y_pred, attentions = m.translate(sub_enc_x, sub_enc_valid_len, dec_vocab=gen.y_vocab, max_len=gen.y_sentence_len)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3d906",
   "metadata": {},
   "source": [
    "## 注意力显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "567d080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from attention import plot_attention_map\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "plot_attention_map(np.squeeze(np.array(attentions), axis=(1, 2, 3)))\n",
    "plt.ylabel(\"predict_step\")\n",
    "plt.xlabel(\"enc_state_weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce4ecd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hop', 'in', '.']  ->  ['monte', '.']\n",
      "['monte', '.']\n",
      " BLEU:  1.0\n",
      "['hop', 'in', '.']  ->  ['montez', '.']\n",
      "['monte', '.']\n",
      " BLEU:  0.7071067811865476\n",
      "['hug', 'me', '.']  ->  ['serre-moi', 'dans', 'tes', 'bras', '!']\n",
      "['serre-moi', 'dans', 'tes', 'bras', '!']\n",
      " BLEU:  1.0\n",
      "['hug', 'me', '.']  ->  ['serrez-moi', 'dans', 'vos', 'bras', '!']\n",
      "['serre-moi', 'dans', 'tes', 'bras', '!']\n",
      " BLEU:  0.0\n",
      "['i', 'fell', '.']  ->  ['je', 'suis', 'tombée', '.']\n",
      "['je', 'suis', 'resté', '.']\n",
      " BLEU:  0.0\n",
      "['i', 'fell', '.']  ->  ['je', 'suis', 'tombé', '.']\n",
      "['je', 'suis', 'resté', '.']\n",
      " BLEU:  0.0\n",
      "['i', 'know', '.']  ->  ['je', 'sais', '.']\n",
      "['je', 'sais', '.']\n",
      " BLEU:  1.0\n",
      "['i', 'left', '.']  ->  ['je', 'suis', 'parti', '.']\n",
      "['je', 'suis', 'partie', '.']\n",
      " BLEU:  0.0\n",
      "['i', 'left', '.']  ->  ['je', 'suis', 'partie', '.']\n",
      "['je', 'suis', 'partie', '.']\n",
      " BLEU:  1.0\n",
      "['i', 'lost', '.']  ->  [\"j'ai\", 'perdu', '.']\n",
      "['je', 'me', 'suis', 'reposé', '.']\n",
      " BLEU:  0.0\n",
      "['i', 'paid', '.']  ->  ['j’ai', 'payé', '.']\n",
      "['j’ai', 'payé', '.']\n",
      " BLEU:  1.0\n",
      "[\"i'm\", '19', '.']  ->  [\"j'ai\", '19', 'ans', '.']\n",
      "[\"j'ai\", '19', 'ans', '.']\n",
      " BLEU:  1.0\n",
      "[\"i'm\", 'ok', '.']  ->  ['je', 'vais', 'bien', '.']\n",
      "['je', 'suis', 'riche', '.']\n",
      " BLEU:  0.0\n",
      "[\"i'm\", 'ok', '.']  ->  ['ça', 'va', '.']\n",
      "['je', 'suis', 'riche', '.']\n",
      " BLEU:  0.0\n",
      "['listen', '.']  ->  ['écoutez', '!']\n",
      "['écoutez', '!']\n",
      " BLEU:  1.0\n",
      "['no', 'way', '!']  ->  [\"c'est\", 'pas', 'possible', '!']\n",
      "[\"c'est\", 'pas', 'possible', '!']\n",
      " BLEU:  1.0\n",
      "['no', 'way', '!']  ->  ['impossible', '!']\n",
      "[\"c'est\", 'pas', 'possible', '!']\n",
      " BLEU:  0.0\n",
      "['no', 'way', '!']  ->  ['en', 'aucun', 'cas', '.']\n",
      "[\"c'est\", 'pas', 'possible', '!']\n",
      " BLEU:  0.0\n",
      "['no', 'way', '!']  ->  ['sans', 'façons', '!']\n",
      "[\"c'est\", 'pas', 'possible', '!']\n",
      " BLEU:  0.0\n",
      "['no', 'way', '!']  ->  [\"c'est\", 'hors', 'de', 'question', '!']\n",
      "[\"c'est\", 'pas', 'possible', '!']\n",
      " BLEU:  0.0\n"
     ]
    }
   ],
   "source": [
    "from translate_model import bleu_acc\n",
    "\n",
    "for i in range(40, 60):\n",
    "    sub_enc_x, sub_enc_valid_len, sub_dec_x, sub_target_valid_len, sub_target_y = gen[i: i + 1]\n",
    "    y_pred, _ = m.translate(sub_enc_x, sub_enc_valid_len, dec_vocab=gen.y_vocab, max_len=gen.y_sentence_len)\n",
    "    x = gen.x_vocab.to_tokens(list(sub_enc_x[0]))[: sub_enc_valid_len[0]]\n",
    "    y_pred = y_pred.split()\n",
    "    label = gen.y_vocab.to_tokens(list(sub_target_y[0]))[: sub_target_valid_len[0] - 1]\n",
    "    print(x, \" -> \", label)\n",
    "    print(y_pred)\n",
    "    print(\" BLEU: \", bleu_acc(label, y_pred, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
